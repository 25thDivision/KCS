import os
import sys
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from tqdm import tqdm
import numpy as np

# [Import] ê³µí†µ ë°ì´í„°ì…‹ ëª¨ë“ˆ
from simulation.common.dataset import QECDataset
# [Import] CNN ëª¨ë¸
from models.cnn import CNN

# ==============================================================================
# ì„¤ì • (CNN ì „ìš©)
# ==============================================================================
DATASET_DIR = "dataset/color_code/image"  # ì´ë¯¸ì§€ ë°ì´í„° ê²½ë¡œ
TRAIN_FILE = "train_d5_p0.05.npz"
TEST_FILE  = "test_d5_p0.05.npz"

# ì €ìž¥í•  ëª¨ë¸ í´ë” ë° íŒŒì¼ëª… ì„¤ì •
MODEL_SAVE_DIR = "saved_weights/cnn"
MODEL_SAVE_NAME = "cnn_d5_p0.05_best.pth"

BATCH_SIZE = 128
LEARNING_RATE = 1e-3
EPOCHS = 10
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

def load_data(file_name):
    path = os.path.join(DATASET_DIR, file_name)
    if not os.path.exists(path):
        raise FileNotFoundError(f"íŒŒì¼ ì—†ìŒ: {path}\n simulation/generate_data_image.pyë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
    data = np.load(path)
    return data['features'], data['labels']

def train_one_epoch(model, loader, optimizer, criterion, device):
    model.train()
    total_loss = 0.0
    
    for inputs, labels in tqdm(loader, desc="Training Epoch", leave=False):
        inputs, labels = inputs.to(device), labels.to(device)
        
        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        
        loss.backward()
        optimizer.step()
        
        total_loss += loss.item()
        
    return total_loss / len(loader)

def evaluate(model, loader, criterion, device):
    model.eval()
    total_loss = 0.0
    total_error_bits = 0
    detected_error_bits = 0
    
    with torch.no_grad():
        for inputs, labels in tqdm(loader, desc="Evaluating", leave=False):
            inputs, labels = inputs.to(device), labels.to(device)
            
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            total_loss += loss.item()
            
            # ì˜ˆì¸¡: Logitì´ 0ë³´ë‹¤ í¬ë©´ ì—ëŸ¬(1)ë¡œ íŒë‹¨
            preds = (outputs > 0).float()
            
            # ì‹¤ì œ ì—ëŸ¬ê°€ ìžˆëŠ” ìœ„ì¹˜(1)ë§Œ ê³¨ë¼ëƒ…ë‹ˆë‹¤
            error_mask = (labels == 1)
            total_error_bits += error_mask.sum().item()
            
            # ì‹¤ì œ ì—ëŸ¬ê°€ ìžˆëŠ” ê³³ ì¤‘ì—ì„œ, ì˜ˆì¸¡ë„ 1ì¸ ê°œìˆ˜ (Recall)
            detected_error_bits += (preds[error_mask] == 1).sum().item()
            
    avg_loss = total_loss / len(loader)
    # ë¶„ëª¨ê°€ 0ì¼ ê²½ìš°(ì—ëŸ¬ê°€ í•˜ë‚˜ë„ ì—†ëŠ” ê²½ìš°) ë°©ì§€
    ecr = detected_error_bits / total_error_bits if total_error_bits > 0 else 0.0
    
    return avg_loss, ecr

def main():
    print(f"=== CNN Training (d=5, p=0.05) on {DEVICE} ===")
    
    # 1. ë°ì´í„° ë¡œë“œ
    X_train, y_train = load_data(TRAIN_FILE)
    X_test, y_test = load_data(TEST_FILE)
    print(f"    Train Shape: {X_train.shape}")
    print(f"    Test Shape:  {X_test.shape}")
    
    # 2. ë¡œë” ìƒì„±
    train_loader = DataLoader(QECDataset(X_train, y_train), batch_size=BATCH_SIZE, shuffle=True)
    test_loader = DataLoader(QECDataset(X_test, y_test), batch_size=BATCH_SIZE, shuffle=False)
    
    # 3. ëª¨ë¸ ì´ˆê¸°í™” (CNN)
    height = X_train.shape[2]
    width = X_train.shape[3]
    num_qubits = y_train.shape[1]
    
    model = CNN(height, width, in_channels=1, num_classes=num_qubits).to(DEVICE)
    
    # ê¸°ì¡´ í•™ìŠµëœ ê°€ì¤‘ì¹˜ ë¶ˆëŸ¬ì˜¤ê¸°
    save_path = os.path.join(MODEL_SAVE_DIR, MODEL_SAVE_NAME)
    
    if os.path.exists(save_path):
        print(f">>> ðŸ”„ Found existing model: {save_path}")
        print(">>> Loading weights and resuming training...")
        try:
            model.load_state_dict(torch.load(save_path))
            print(">>> âœ… Weights loaded successfully!")
        except Exception as e:
            print(f">>> âš ï¸ Failed to load weights: {e}")
            print(">>> Starting from scratch.")
    else:
        print(">>> No existing model found. Starting from scratch.")
    
    # [ì„¤ì •] í´ëž˜ìŠ¤ ë¶ˆê· í˜• í•´ê²°ì„ ìœ„í•œ pos_weight (ì„ íƒ ì‚¬í•­, í•„ìš”ì‹œ í™œì„±í™”)
    # p=0.05 ê¸°ì¤€, 0ì´ 1ë³´ë‹¤ ì•½ 19ë°° ë§ŽìŒ -> 19.0ë°° ê°€ì¤‘ì¹˜ ë¶€ì—¬
    pos_weight_val = (1.0 - 0.05) / 0.05 
    pos_weight = torch.tensor([pos_weight_val] * num_qubits).to(DEVICE)
    
    # ê°€ì¤‘ì¹˜ ì ìš©ëœ ì†ì‹¤ í•¨ìˆ˜
    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)
    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)
    
    # [ì¶”ê°€] ëª¨ë¸ ì €ìž¥ í´ë” ìƒì„±
    if not os.path.exists(MODEL_SAVE_DIR):
        os.makedirs(MODEL_SAVE_DIR)
        print(f">>> Created directory: {MODEL_SAVE_DIR}")

    # 4. í•™ìŠµ ë£¨í”„
    print(">>> Starting Training...")
    best_ecr = 0.0
    
    for epoch in range(EPOCHS):
        train_loss = train_one_epoch(model, train_loader, optimizer, criterion, DEVICE)
        val_loss, val_ecr = evaluate(model, test_loader, criterion, DEVICE)
        
        print(f"Epoch [{epoch+1}/{EPOCHS}] "
              f"Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | ECR (Recall): {val_ecr:.2%}")
        
        # [ì¶”ê°€] Best Model ì €ìž¥ ë¡œì§
        if val_ecr > best_ecr:
            best_ecr = val_ecr
            save_path = os.path.join(MODEL_SAVE_DIR, MODEL_SAVE_NAME)
            torch.save(model.state_dict(), save_path)
            print(f"    -> ðŸ’¾ New Best Model Saved! (ECR: {best_ecr:.2%}) at {save_path}")

    print(f"\n>>> CNN Training Complete. Best ECR: {best_ecr:.2%}")

if __name__ == "__main__":
    main()